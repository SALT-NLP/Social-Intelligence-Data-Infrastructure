Loading vocab...
token_vocab: 2470, post_vocab: 138, pos_vocab: 48, dep_vocab: 46, pol_vocab: 3
cuda memory allocated: 1838679040
n_trainable_params: 211083, n_nontrainable_params: 344700
training arguments:
>>> model_name: dualgcn
>>> dataset: mamssmall
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f7b292b9940>
>>> learning_rate: 0.002
>>> l2reg: 0.0001
>>> num_epoch: 50
>>> batch_size: 16
>>> log_step: 5
>>> embed_dim: 300
>>> post_dim: 30
>>> pos_dim: 30
>>> hidden_dim: 50
>>> num_layers: 2
>>> polarities_dim: 3
>>> input_dropout: 0.7
>>> gcn_dropout: 0.1
>>> lower: True
>>> direct: False
>>> loop: True
>>> bidirect: True
>>> rnn_hidden: 50
>>> rnn_layers: 1
>>> rnn_dropout: 0.1
>>> attention_heads: 1
>>> max_length: 85
>>> device: cuda:0
>>> seed: 1000
>>> weight_decay: 0.0
>>> vocab_dir: ./DualGCN/dataset/MAMS_small
>>> pad_id: 0
>>> parseadj: True
>>> parsehead: False
>>> cuda: 0
>>> losstype: doubleloss
>>> alpha: 0.2
>>> beta: 0.3
>>> pretrained_bert_name: bert-base-uncased
>>> adam_epsilon: 1e-08
>>> bert_dim: 768
>>> bert_dropout: 0.3
>>> diff_lr: False
>>> bert_lr: 2e-05
>>> model_class: <class 'models.dualgcn.DualGCNClassifier'>
>>> dataset_file: {'train': './DualGCN/dataset/MAMS_small/test_xpos2.json', 'test': './DualGCN/dataset/MAMS_small/test_xpos3.json'}
>>> inputs_cols: ['text', 'aspect', 'pos', 'head', 'deprel', 'post', 'mask', 'length', 'adj']
>>> post_size: 138
>>> pos_size: 48
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>> saved: ./DualGCN/state_dict/dualgcn_mamssmall_acc_0.2994_f1_0.1536
loss: 1.4913, acc: 0.3125, test_acc: 0.2994, f1: 0.1536
>> saved: ./DualGCN/state_dict/dualgcn_mamssmall_acc_0.3683_f1_0.2805
loss: 1.4716, acc: 0.2500, test_acc: 0.3683, f1: 0.2805
>> saved: ./DualGCN/state_dict/dualgcn_mamssmall_acc_0.4454_f1_0.2757
loss: 1.4527, acc: 0.2292, test_acc: 0.4454, f1: 0.2757
loss: 1.5078, acc: 0.2500, test_acc: 0.3930, f1: 0.2863
loss: 1.3984, acc: 0.2750, test_acc: 0.4154, f1: 0.2924
>> saved: ./DualGCN/state_dict/dualgcn_mamssmall_acc_0.4558_f1_0.2611
loss: 1.3798, acc: 0.3021, test_acc: 0.4558, f1: 0.2611
loss: 1.5553, acc: 0.2857, test_acc: 0.4551, f1: 0.2117
loss: 1.5406, acc: 0.2734, test_acc: 0.4543, f1: 0.2083
loss: 1.4247, acc: 0.2778, test_acc: 0.4551, f1: 0.2132
>> saved: ./DualGCN/state_dict/dualgcn_mamssmall_acc_0.4603_f1_0.2359
loss: 1.3580, acc: 0.2938, test_acc: 0.4603, f1: 0.2359
>> saved: ./DualGCN/state_dict/dualgcn_mamssmall_acc_0.4611_f1_0.2309
loss: 1.3928, acc: 0.3068, test_acc: 0.4611, f1: 0.2309
loss: 1.4156, acc: 0.2969, test_acc: 0.4543, f1: 0.2083
