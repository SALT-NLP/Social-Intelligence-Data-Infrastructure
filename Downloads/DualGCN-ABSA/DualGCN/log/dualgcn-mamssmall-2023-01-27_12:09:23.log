Loading vocab...
token_vocab: 236, post_vocab: 86, pos_vocab: 34, dep_vocab: 35, pol_vocab: 3
cuda memory allocated: 1838656512
n_trainable_params: 209103, n_nontrainable_params: 344700
training arguments:
>>> model_name: dualgcn
>>> dataset: mamssmall
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f5c384e0940>
>>> learning_rate: 0.002
>>> l2reg: 0.0001
>>> num_epoch: 50
>>> batch_size: 16
>>> log_step: 5
>>> embed_dim: 300
>>> post_dim: 30
>>> pos_dim: 30
>>> hidden_dim: 50
>>> num_layers: 2
>>> polarities_dim: 3
>>> input_dropout: 0.7
>>> gcn_dropout: 0.1
>>> lower: True
>>> direct: False
>>> loop: True
>>> bidirect: True
>>> rnn_hidden: 50
>>> rnn_layers: 1
>>> rnn_dropout: 0.1
>>> attention_heads: 1
>>> max_length: 85
>>> device: cuda:0
>>> seed: 1000
>>> weight_decay: 0.0
>>> vocab_dir: ./DualGCN/dataset/MAMS_small
>>> pad_id: 0
>>> parseadj: True
>>> parsehead: False
>>> cuda: 0
>>> losstype: doubleloss
>>> alpha: 0.2
>>> beta: 0.3
>>> pretrained_bert_name: bert-base-uncased
>>> adam_epsilon: 1e-08
>>> bert_dim: 768
>>> bert_dropout: 0.3
>>> diff_lr: False
>>> bert_lr: 2e-05
>>> model_class: <class 'models.dualgcn.DualGCNClassifier'>
>>> dataset_file: {'train': './DualGCN/dataset/MAMS_small/train.json', 'test': './DualGCN/dataset/MAMS_small/test.json'}
>>> inputs_cols: ['text', 'aspect', 'pos', 'head', 'deprel', 'post', 'mask', 'length', 'adj']
>>> post_size: 86
>>> pos_size: 34
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
>> saved: ./DualGCN/state_dict/dualgcn_mamssmall_acc_0.2353_f1_0.1270
loss: 1.3465, acc: 0.4375, test_acc: 0.2353, f1: 0.1270
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 1.3051, acc: 0.3333, test_acc: 0.2353, f1: 0.1689
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 5
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 6
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 7
loss: 1.2734, acc: 0.4375, test_acc: 0.2353, f1: 0.1689
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 8
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 9
loss: 1.2871, acc: 0.3333, test_acc: 0.2353, f1: 0.1689
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 10
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 11
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 12
loss: 1.2251, acc: 0.4375, test_acc: 0.2353, f1: 0.1689
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 13
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 14
loss: 1.2271, acc: 0.4167, test_acc: 0.2353, f1: 0.1689
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 15
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 16
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 17
loss: 1.1139, acc: 0.5000, test_acc: 0.2353, f1: 0.1333
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 18
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 19
>> saved: ./DualGCN/state_dict/dualgcn_mamssmall_acc_0.2941_f1_0.2222
loss: 1.1841, acc: 0.5000, test_acc: 0.2941, f1: 0.2222
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 20
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 21
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 22
loss: 1.1618, acc: 0.4375, test_acc: 0.2353, f1: 0.1778
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 23
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 24
loss: 1.1669, acc: 0.5000, test_acc: 0.2353, f1: 0.1726
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 25
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 26
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 27
loss: 0.9624, acc: 0.7500, test_acc: 0.2941, f1: 0.2202
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 28
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 29
>> saved: ./DualGCN/state_dict/dualgcn_mamssmall_acc_0.3529_f1_0.2679
loss: 1.0584, acc: 0.5833, test_acc: 0.3529, f1: 0.2679
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 30
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 31
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 32
loss: 1.0656, acc: 0.6250, test_acc: 0.2941, f1: 0.2081
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 33
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 34
loss: 1.0592, acc: 0.7500, test_acc: 0.2941, f1: 0.2202
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 35
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 36
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 37
loss: 0.9858, acc: 0.6250, test_acc: 0.2941, f1: 0.2202
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 38
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 39
loss: 1.0845, acc: 0.5833, test_acc: 0.3529, f1: 0.2680
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 40
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 41
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 42
loss: 1.0330, acc: 0.6875, test_acc: 0.2941, f1: 0.2202
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 43
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 44
loss: 1.0168, acc: 0.4167, test_acc: 0.2353, f1: 0.1778
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 45
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 46
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 47
loss: 0.9844, acc: 0.6250, test_acc: 0.2941, f1: 0.2222
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 48
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 49
loss: 0.9585, acc: 0.7500, test_acc: 0.2941, f1: 0.2202
max_test_acc: 0.35294117647058826, max_f1: 0.2679738562091503
>> saved: ./DualGCN/state_dict/dualgcn_mamssmall_acc_0.3529_f1_0.2679
############################################################
max_test_acc_overall:0.35294117647058826
max_f1_overall:0.2679738562091503
Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.2500    0.7500    0.3750         4
           1     0.0000    0.0000    0.0000         4
           2     0.6000    0.3333    0.4286         9

    accuracy                         0.3529        17
   macro avg     0.2833    0.3611    0.2679        17
weighted avg     0.3765    0.3529    0.3151        17

Confusion Matrix...
[[3 0 1]
 [3 0 1]
 [6 0 3]]
